{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "photographic-radius",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: ecCodes 2.21.0 or higher is recommended. You are running version 2.16.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import csv\n",
    "import xarray as xr\n",
    "import fsspec\n",
    "import zarr\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "from pytorch_lightning import LightningModule\n",
    "from torchmetrics.classification.accuracy import Accuracy\n",
    "from torchmetrics import AUC, ConfusionMatrix, AUROC, AveragePrecision\n",
    "from wildfire_forecasting.models.greece_fire_models import LSTM_fire_model, ConvLSTM_fire_model\n",
    "# from wildfire_forecasting.models.modules.greece_fire_models import LSTM_fire_model, ConvLSTM_fire_model \n",
    "\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "import gc\n",
    "\n",
    "random.seed(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "favorite-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = ['time',\n",
    " 'x',\n",
    " 'y',\n",
    "]\n",
    "\n",
    "all_dynamic_features = [\n",
    " '1 km 16 days NDVI',\n",
    " 'LST_Day_1km',\n",
    " 'LST_Night_1km',\n",
    " 'era5_max_d2m',\n",
    " 'era5_max_t2m',\n",
    " 'era5_max_sp',\n",
    " 'era5_max_tp',\n",
    " 'sminx',\n",
    " 'era5_max_wind_speed',\n",
    " 'era5_min_rh']\n",
    "\n",
    "all_dynamic_features_bolam = [\n",
    " '1 km 16 days NDVI',\n",
    " 'LST_Day_1km',\n",
    " 'LST_Night_1km',\n",
    " 'era5_max_d2m',\n",
    " 'era5_max_t2m',\n",
    " 'era5_max_tp',\n",
    " 'sminx',\n",
    " 'era5_max_wind_speed',\n",
    " 'era5_min_rh']\n",
    "\n",
    "all_static_features = [\n",
    " 'dem_mean',\n",
    " 'slope_mean',\n",
    " 'roads_distance',\n",
    " 'waterway_distance',\n",
    " 'population_density'\n",
    "]\n",
    "\n",
    "all_categorical_features = 'clc_vec'\n",
    "len_clc = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "communist-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_settings = {\n",
    "    'lstm' : {'dynamic_features':all_dynamic_features, 'static_features':all_static_features, 'hidden_size':64, 'lstm_layers':1, 'dropout':0.5}\n",
    "}\n",
    "\n",
    "best_settings_bolam = {\n",
    "    'lstm_bolam' : {'dynamic_features':all_dynamic_features_bolam, 'static_features':all_static_features, 'hidden_size':64, 'lstm_layers':1, 'dropout':0.5}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "planned-principal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Follow readme for downloading the models and complete the models path here\n",
    "models_path = Path.home() / 'hdd1/iprapas/uc3/models'\n",
    "models_path_bolam = Path.home() / 'hdd1/diogenis/observatory/wildfire_forecasting/logs/runs/2022-09-20/13-44-33/checkpoints'\n",
    "model = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "basic-allen",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd1/diogenis/observatory/meteo/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/mnt/hdd1/diogenis/observatory/meteo/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTM_fire_model(\n",
       "  (model): SimpleLSTM(\n",
       "    (ln1): LayerNorm((25,), eps=1e-05, elementwise_affine=True)\n",
       "    (lstm): LSTM(25, 64, batch_first=True)\n",
       "    (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (drop1): Dropout(p=0.5, inplace=False)\n",
       "    (relu): ReLU()\n",
       "    (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (drop2): Dropout(p=0.5, inplace=False)\n",
       "    (fc3): Linear(in_features=32, out_features=2, bias=True)\n",
       "    (fc_nn): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=32, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (criterion): NLLLoss()\n",
       "  (train_accuracy): Accuracy()\n",
       "  (train_auc): AUROC()\n",
       "  (train_auprc): AveragePrecision()\n",
       "  (val_accuracy): Accuracy()\n",
       "  (val_auc): AUROC()\n",
       "  (val_auprc): AveragePrecision()\n",
       "  (test_accuracy): Accuracy()\n",
       "  (test_auc): AUROC()\n",
       "  (test_auprc): AveragePrecision()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['lstm'] = LSTM_fire_model(**best_settings['lstm']).load_from_checkpoint(models_path / 'lstm.ckpt')\n",
    "model['lstm'].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "athletic-nudist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_fire_model(\n",
       "  (model): SimpleLSTM(\n",
       "    (ln1): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "    (lstm): LSTM(24, 64, batch_first=True)\n",
       "    (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (drop1): Dropout(p=0.5, inplace=False)\n",
       "    (relu): ReLU()\n",
       "    (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (drop2): Dropout(p=0.5, inplace=False)\n",
       "    (fc3): Linear(in_features=32, out_features=2, bias=True)\n",
       "    (fc_nn): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=32, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (criterion): NLLLoss()\n",
       "  (train_accuracy): Accuracy()\n",
       "  (train_auc): AUROC()\n",
       "  (train_auprc): AveragePrecision()\n",
       "  (val_accuracy): Accuracy()\n",
       "  (val_auc): AUROC()\n",
       "  (val_auprc): AveragePrecision()\n",
       "  (test_accuracy): Accuracy()\n",
       "  (test_auc): AUROC()\n",
       "  (test_auprc): AveragePrecision()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['lstm_bolam'] = LSTM_fire_model(**best_settings_bolam['lstm_bolam']).load_from_checkpoint(models_path_bolam / 'last.ckpt')\n",
    "model['lstm_bolam'].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "funded-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = Path.home() / 'hdd1/diogenis/observatory'\n",
    "\n",
    "minmax_dataset_root = Path.home() / 'jh-shared/skondylatos/datasets'\n",
    "\n",
    "variable_dict_path = dataset_root / 'variable_dict.json' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "successful-chicago",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(variable_dict_path) as f:\n",
    "    variable_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "figured-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(minmax_dataset_root / 'minmax_clc_v3.json') as f:\n",
    "    min_max_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fiscal-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireDataset_npy(Dataset):\n",
    "    def __init__(self,  src, access_mode: str = 'temporal',\n",
    "                 problem_class: str = 'classification',\n",
    "                 train_val_test: str = 'test', dynamic_features: list = None, static_features: list = None,\n",
    "                 categorical_features: list = None, nan_fill: float = -1., neg_pos_ratio: int = 2, clc: str = None):\n",
    "        \"\"\"\n",
    "        @param access_mode: spatial, temporal or spatiotemporal\n",
    "        @param problem_class: classification or segmentation\n",
    "        @param train_val_test:\n",
    "                'train' gets samples from [2009-2018].\n",
    "                'val' gets samples from 2019.\n",
    "                test' get samples from 2020\n",
    "        @param dynamic_features: selects the dynamic features to return\n",
    "        @param static_features: selects the static features to return\n",
    "        @param categorical_features: selects the categorical features\n",
    "        @param nan_fill: Fills nan with the value specified here\n",
    "        \"\"\"\n",
    "        if static_features is None:\n",
    "            static_features = all_static_features\n",
    "        if dynamic_features is None:\n",
    "            dynamic_features = all_dynamic_features\n",
    "            \n",
    "        self.static_features = static_features\n",
    "        self.dynamic_features = dynamic_features\n",
    "        self.categorical_features = categorical_features\n",
    "        self.access_mode = access_mode\n",
    "        self.problem_class = problem_class\n",
    "        self.nan_fill = nan_fill\n",
    "        self.clc = clc\n",
    "        self.src = src\n",
    "        \n",
    "        assert problem_class in ['classification', 'segmentation']\n",
    "        if problem_class == 'classification':\n",
    "            self.target = 'burned'\n",
    "        else:\n",
    "            self.target = 'burned_areas'\n",
    "            \n",
    "        assert self.access_mode in ['spatial', 'temporal', 'spatiotemporal']\n",
    "        \n",
    "        dataset_path = dataset_root\n",
    "        if self.src == 'bolam':\n",
    "            self.positives_list = list((dataset_path / 'positives_bolam').glob('*dynamic.npy'))\n",
    "            self.negatives_list = list((dataset_path / 'negatives_bolam').glob('*dynamic.npy'))\n",
    "        else:\n",
    "            self.positives_list = list((dataset_path / 'positives_era5_bolam').glob('*dynamic.npy'))\n",
    "            self.negatives_list = list((dataset_path / 'negatives_era5_bolam').glob('*dynamic.npy'))\n",
    "        \n",
    "        self.positives_list = list(zip(self.positives_list, [1] * (len(self.positives_list))))\n",
    "        self.negatives_list = list(zip(self.negatives_list, [0] * (len(self.negatives_list))))\n",
    "        \n",
    "        val_year = 2020\n",
    "        test_year = min(val_year + 1, 2021)\n",
    "\n",
    "        self.test_positive_list = [(x, y) for (x, y) in self.positives_list if int(x.stem[:4]) == test_year]\n",
    "        self.test_negative_list = random.sample(\n",
    "            [(x, y) for (x, y) in self.negatives_list if int(x.stem[:4]) == test_year],\n",
    "            8638)\n",
    "\n",
    "        self.dynamic_idxfeat = [(i, feat) for i, feat in enumerate(variable_dict['dynamic']) if\n",
    "                                feat in self.dynamic_features]\n",
    "        self.static_idxfeat = [(i, feat) for i, feat in enumerate(variable_dict['static']) if\n",
    "                               feat in self.static_features]\n",
    "        \n",
    "        self.dynamic_idx = [x for (x, _) in self.dynamic_idxfeat]\n",
    "        self.static_idx = [x for (x, _) in self.static_idxfeat]\n",
    "\n",
    "        if train_val_test == 'train':\n",
    "            print(f'Positives: {len(self.train_positive_list)} / Negatives: {len(self.train_negative_list)}')\n",
    "            self.path_list = self.train_positive_list + self.train_negative_list\n",
    "        elif train_val_test == 'val':\n",
    "            print(f'Positives: {len(self.val_positive_list)} / Negatives: {len(self.val_negative_list)}')\n",
    "            self.path_list = self.val_positive_list + self.val_negative_list\n",
    "        elif train_val_test == 'test':\n",
    "            print(f'Positives: {len(self.test_positive_list)} / Negatives: {len(self.test_negative_list)}')\n",
    "            self.path_list = self.test_positive_list + self.test_negative_list\n",
    "            \n",
    "        print(\"Dataset length\", len(self.path_list))\n",
    "        \n",
    "        random.shuffle(self.path_list)\n",
    "        \n",
    "        self.mm_dict = self._min_max_vec()\n",
    "\n",
    "    def _min_max_vec(self):\n",
    "        mm_dict = {'min': {}, 'max': {}}\n",
    "        for agg in ['min', 'max']:\n",
    "            if self.access_mode == 'spatial':\n",
    "                mm_dict[agg]['dynamic'] = np.ones((len(self.dynamic_features), 1, 1))\n",
    "                mm_dict[agg]['static'] = np.ones((len(self.static_features), 1, 1))\n",
    "                for i, (_, feat) in enumerate(self.dynamic_idxfeat):\n",
    "                    mm_dict[agg]['dynamic'][i, :, :] = min_max_dict[agg][self.access_mode][feat]\n",
    "                for i, (_, feat) in enumerate(self.static_idxfeat):\n",
    "                    mm_dict[agg]['static'][i, :, :] = min_max_dict[agg][self.access_mode][feat]\n",
    "\n",
    "            if self.access_mode == 'temporal':\n",
    "                mm_dict[agg]['dynamic'] = np.ones((1, len(self.dynamic_features)))\n",
    "                mm_dict[agg]['static'] = np.ones((len(self.static_features)))\n",
    "                for i, (_, feat) in enumerate(self.dynamic_idxfeat):\n",
    "                    mm_dict[agg]['dynamic'][:, i] = min_max_dict[agg][self.access_mode][feat]\n",
    "                for i, (_, feat) in enumerate(self.static_idxfeat):\n",
    "                    mm_dict[agg]['static'][i] = min_max_dict[agg][self.access_mode][feat]\n",
    "\n",
    "            if self.access_mode == 'spatiotemporal':\n",
    "                mm_dict[agg]['dynamic'] = np.ones((1, len(self.dynamic_features), 1, 1))\n",
    "                mm_dict[agg]['static'] = np.ones((len(self.static_features), 1, 1))\n",
    "                for i, (_, feat) in enumerate(self.dynamic_idxfeat):\n",
    "                    mm_dict[agg]['dynamic'][:, i, :, :] = min_max_dict[agg][self.access_mode][feat]\n",
    "                for i, (_, feat) in enumerate(self.static_idxfeat):\n",
    "                    mm_dict[agg]['static'][i, :, :] = min_max_dict[agg][self.access_mode][feat]\n",
    "        return mm_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, labels = self.path_list[idx]\n",
    "        dynamic = np.load(path)\n",
    "        static = np.load(str(path).replace('dynamic', 'static'))\n",
    "        \n",
    "        if self.access_mode == 'spatial':\n",
    "            dynamic = dynamic[self.dynamic_idx]\n",
    "            static = static[self.static_idx]\n",
    "        elif self.access_mode == 'temporal':\n",
    "            dynamic = dynamic[:, self.dynamic_idx, ...]\n",
    "            static = static[self.static_idx]\n",
    "        else:\n",
    "            dynamic = dynamic[:, self.dynamic_idx, ...]\n",
    "            static = static[self.static_idx]\n",
    "\n",
    "        def _min_max_scaling(in_vec, max_vec, min_vec):\n",
    "            return (in_vec - min_vec) / (max_vec - min_vec)\n",
    "\n",
    "        dynamic = _min_max_scaling(dynamic, self.mm_dict['max']['dynamic'], self.mm_dict['min']['dynamic'])\n",
    "        static = _min_max_scaling(static, self.mm_dict['max']['static'], self.mm_dict['min']['static'])\n",
    "\n",
    "        if self.access_mode == 'temporal':\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "                feat_mean = np.nanmean(dynamic, axis=0)\n",
    "                # Find indices that you need to replace\n",
    "                inds = np.where(np.isnan(dynamic))\n",
    "                # Place column means in the indices. Align the arrays using take\n",
    "                dynamic[inds] = np.take(feat_mean, inds[1])\n",
    "\n",
    "        elif self.access_mode == 'spatiotemporal':\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "                feat_mean = np.nanmean(dynamic, axis=(2, 3))\n",
    "                feat_mean = feat_mean[..., np.newaxis, np.newaxis]\n",
    "                feat_mean = np.repeat(feat_mean, dynamic.shape[2], axis=2)\n",
    "                feat_mean = np.repeat(feat_mean, dynamic.shape[3], axis=3)\n",
    "                dynamic = np.where(np.isnan(dynamic), feat_mean, dynamic)\n",
    "        if self.nan_fill:\n",
    "            dynamic = np.nan_to_num(dynamic, nan=self.nan_fill)\n",
    "            static = np.nan_to_num(static, nan=self.nan_fill)\n",
    "\n",
    "        if self.clc == 'mode':\n",
    "            clc = np.load(str(path).replace('dynamic', 'clc_mode'))\n",
    "        elif self.clc == 'vec':\n",
    "            clc = np.load(str(path).replace('dynamic', 'clc_vec'))\n",
    "            clc = np.nan_to_num(clc, nan=0)\n",
    "        else:\n",
    "            clc = 0\n",
    "        return dynamic, static, clc, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "voluntary-junction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positives: 4319 / Negatives: 8638\n",
      "Dataset length 12957\n",
      "Positives: 4319 / Negatives: 8638\n",
      "Dataset length 12957\n",
      "Positives: 4319 / Negatives: 8638\n",
      "Dataset length 12957\n",
      "Positives: 4319 / Negatives: 8638\n",
      "Dataset length 12957\n"
     ]
    }
   ],
   "source": [
    "cuda_device = 1\n",
    "positive_weight = 0.5\n",
    "device = torch.device(\"cuda:\" + str(cuda_device) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "weights = [1 - positive_weight, positive_weight]\n",
    "class_weights = torch.FloatTensor(weights)\n",
    "criterion = nn.NLLLoss(weight=class_weights)\n",
    "num_epochs=40\n",
    "\n",
    "dataloaders = {}\n",
    "\n",
    "dataloaders['lstm'] ={'bolam' : torch.utils.data.DataLoader(FireDataset_npy('bolam', train_val_test='test', access_mode = 'temporal', clc = 'vec'), batch_size=256, num_workers=16),\n",
    "                      'era5' : torch.utils.data.DataLoader(FireDataset_npy('era5', train_val_test='test', access_mode = 'temporal', clc = 'vec'), batch_size=256, num_workers=16)}\n",
    "\n",
    "dataloaders['lstm_bolam'] = {'bolam_2' : torch.utils.data.DataLoader(FireDataset_npy('bolam', train_val_test='test', access_mode = 'temporal', clc = 'vec', dynamic_features = all_dynamic_features_bolam), batch_size=256, num_workers=16),\n",
    "                           'era5_2': torch.utils.data.DataLoader(FireDataset_npy('era5', train_val_test='test', access_mode = 'temporal', clc = 'vec', dynamic_features = all_dynamic_features_bolam), batch_size=256, num_workers=16)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "solar-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision_and_recall(output, labels, running_true_positives_fire, running_false_positives_fire, running_false_negatives_fire, running_true_positives_non_fire, running_false_positives_non_fire, running_false_negatives_non_fire):\n",
    "    for j in range(output.size()[0]):\n",
    "        if output[j] == 1 and labels[j] == 1:\n",
    "            running_true_positives_fire +=1\n",
    "        if output[j] == 1 and labels[j] == 0:\n",
    "            running_false_positives_fire +=1\n",
    "        if output[j] == 0 and labels[j] == 1:\n",
    "            running_false_negatives_fire +=1\n",
    "        if output[j] == 0 and labels[j] == 0:\n",
    "            running_true_positives_non_fire +=1\n",
    "        if output[j] == 0 and labels[j] == 1:\n",
    "            running_false_positives_non_fire +=1\n",
    "        if output[j] == 1 and labels[j] == 0:\n",
    "            running_false_negatives_non_fire +=1\n",
    "    return running_true_positives_fire, running_false_positives_fire, running_false_negatives_fire, running_true_positives_non_fire, running_false_positives_non_fire, running_false_negatives_non_fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "crazy-recommendation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:03<00:00, 13.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bolam Loss: 0.4146, Accuracy: 0.8321, PrecisionFire: 0.7147, RecallFire: 0.8263, F1Fire: 0.766455, PrecisionNonFire: 0.9058, RecallNonFire: 0.8350, F1NonFire: 0.868984, AUC: 0.912188, AUPRC: 0.826506 in 0.0645m\n",
      "Confusion Matrix\n",
      "7213 1425\n",
      "750 3569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:02<00:00, 17.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "era5 Loss: 0.2635, Accuracy: 0.8934, PrecisionFire: 0.8233, RecallFire: 0.8662, F1Fire: 0.844184, PrecisionNonFire: 0.9313, RecallNonFire: 0.9070, F1NonFire: 0.919008, AUC: 0.955644, AUPRC: 0.915685 in 0.1130m\n",
      "Confusion Matrix\n",
      "7835 803\n",
      "578 3741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "since = time.time()\n",
    "\n",
    "for data in ['bolam', 'era5']:\n",
    "    preds = []\n",
    "    true_labels = []\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    running_true_positives_fire = 0\n",
    "    running_false_positives_fire = 0\n",
    "    running_false_negatives_fire = 0\n",
    "    running_true_positives_non_fire = 0\n",
    "    running_false_positives_non_fire = 0\n",
    "    running_false_negatives_non_fire = 0\n",
    "    # Iterate over data.\n",
    "    for i, (dynamic, static, clc, labels) in enumerate(tqdm(dataloaders['lstm'][data])):\n",
    "        static = static.unsqueeze(1).repeat(1, dynamic.shape[1], 1)\n",
    "        clc = clc.unsqueeze(1).repeat(1, dynamic.shape[1], 1)\n",
    "        input_ = torch.cat([dynamic, static, clc], dim = 2).float()\n",
    "        with torch.set_grad_enabled(data == 'train'):\n",
    "            outputs_list = []\n",
    "            outputs_list.append(model['lstm'](input_))\n",
    "            outputs = torch.stack(outputs_list, dim=1)\n",
    "            mean = outputs.mean(1)\n",
    "            loss = criterion(mean, labels)\n",
    "        # statistics\n",
    "        running_loss += loss.item() * dynamic.size(0)\n",
    "        output = mean\n",
    "\n",
    "        preds.append(output[:,1])\n",
    "        true_labels.append(labels)\n",
    "        output = torch.argmax(output, dim=1)\n",
    "\n",
    "        correct = (output == labels).float().sum()\n",
    "        running_corrects += correct\n",
    "\n",
    "        running_true_positives_fire, running_false_positives_fire, running_false_negatives_fire, running_true_positives_non_fire, running_false_positives_non_fire, running_false_negatives_non_fire = get_precision_and_recall(output, labels, running_true_positives_fire, running_false_positives_fire, running_false_negatives_fire, running_true_positives_non_fire, running_false_positives_non_fire, running_false_negatives_non_fire)\n",
    "\n",
    "    preds = torch.cat(preds, dim=0).detach().cpu().numpy()\n",
    "    true_labels = torch.cat(true_labels, dim=0).detach().cpu().numpy()\n",
    "    \n",
    "    auc = roc_auc_score(true_labels, preds)\n",
    "    aucpr = average_precision_score(true_labels, preds)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloaders['lstm'][data].dataset)\n",
    "    time_elapsed = time.time() - since\n",
    "\n",
    "    print('{} Loss: {:.4f}, Accuracy: {:.4f}, PrecisionFire: {:.4f}, RecallFire: {:.4f}, F1Fire: {:4f}, PrecisionNonFire: {:.4f}, RecallNonFire: {:.4f}, F1NonFire: {:4f}, AUC: {:4f}, AUPRC: {:4f} in {:.4f}m'.format(data, \n",
    "                                                                                  epoch_loss, running_corrects/len(dataloaders['lstm'][data].dataset),\n",
    "                                                                                  running_true_positives_fire/(running_true_positives_fire + running_false_positives_fire),\n",
    "                                                                                  running_true_positives_fire/(running_true_positives_fire + running_false_negatives_fire),\n",
    "                                                                                  running_true_positives_fire/(running_true_positives_fire + (1/2)*(running_false_positives_fire + running_false_negatives_fire)),\n",
    "                                                                                  running_true_positives_non_fire/(running_true_positives_non_fire + running_false_positives_non_fire),\n",
    "                                                                                  running_true_positives_non_fire/(running_true_positives_non_fire + running_false_negatives_non_fire),\n",
    "                                                                                  running_true_positives_non_fire/(running_true_positives_non_fire + (1/2)*(running_false_positives_non_fire + running_false_negatives_non_fire)),\n",
    "                                                                                  auc, aucpr, time_elapsed/60))\n",
    "\n",
    "    print('Confusion Matrix')\n",
    "    print(running_true_positives_non_fire, running_false_negatives_non_fire)\n",
    "    print(running_false_negatives_fire, running_true_positives_fire)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "boxed-cosmetic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:02<00:00, 21.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bolam_2 Loss: 0.4084, Accuracy: 0.8353, PrecisionFire: 0.7072, RecallFire: 0.8634, F1Fire: 0.777523, PrecisionNonFire: 0.9232, RecallNonFire: 0.8213, F1NonFire: 0.869256, AUC: 0.917479, AUPRC: 0.824759 in 0.0391m\n",
      "Confusion Matrix\n",
      "7094 1544\n",
      "590 3729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:02<00:00, 20.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "era5_2 Loss: 0.2740, Accuracy: 0.8844, PrecisionFire: 0.7903, RecallFire: 0.8891, F1Fire: 0.836784, PrecisionNonFire: 0.9408, RecallNonFire: 0.8820, F1NonFire: 0.910492, AUC: 0.955511, AUPRC: 0.917751 in 0.0809m\n",
      "Confusion Matrix\n",
      "7619 1019\n",
      "479 3840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "since = time.time()\n",
    "\n",
    "for data in ['bolam_2', 'era5_2']:\n",
    "    preds = []\n",
    "    true_labels = []\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    running_true_positives_fire = 0\n",
    "    running_false_positives_fire = 0\n",
    "    running_false_negatives_fire = 0\n",
    "    running_true_positives_non_fire = 0\n",
    "    running_false_positives_non_fire = 0\n",
    "    running_false_negatives_non_fire = 0\n",
    "    # Iterate over data.\n",
    "    for i, (dynamic, static, clc, labels) in enumerate(tqdm(dataloaders['lstm_bolam'][data])):\n",
    "        static = static.unsqueeze(1).repeat(1, dynamic.shape[1], 1)\n",
    "        clc = clc.unsqueeze(1).repeat(1, dynamic.shape[1], 1)\n",
    "        input_ = torch.cat([dynamic, static, clc], dim = 2).float()\n",
    "        with torch.set_grad_enabled(data == 'train'):\n",
    "            outputs_list = []\n",
    "            outputs_list.append(model['lstm_bolam'](input_))\n",
    "            outputs = torch.stack(outputs_list, dim=1)\n",
    "            mean = outputs.mean(1)\n",
    "            loss = criterion(mean, labels)\n",
    "        # statistics\n",
    "        running_loss += loss.item() * dynamic.size(0)\n",
    "        output = mean\n",
    "\n",
    "        preds.append(output[:,1])\n",
    "        true_labels.append(labels)\n",
    "        output = torch.argmax(output, dim=1)\n",
    "\n",
    "        correct = (output == labels).float().sum()\n",
    "        running_corrects += correct\n",
    "\n",
    "        running_true_positives_fire, running_false_positives_fire, running_false_negatives_fire, running_true_positives_non_fire, running_false_positives_non_fire, running_false_negatives_non_fire = get_precision_and_recall(output, labels, running_true_positives_fire, running_false_positives_fire, running_false_negatives_fire, running_true_positives_non_fire, running_false_positives_non_fire, running_false_negatives_non_fire)\n",
    "\n",
    "    preds = torch.cat(preds, dim=0).detach().cpu().numpy()\n",
    "    true_labels = torch.cat(true_labels, dim=0).detach().cpu().numpy()\n",
    "    \n",
    "    auc = roc_auc_score(true_labels, preds)\n",
    "    aucpr = average_precision_score(true_labels, preds)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloaders['lstm_bolam'][data].dataset)\n",
    "    time_elapsed = time.time() - since\n",
    "\n",
    "    print('{} Loss: {:.4f}, Accuracy: {:.4f}, PrecisionFire: {:.4f}, RecallFire: {:.4f}, F1Fire: {:4f}, PrecisionNonFire: {:.4f}, RecallNonFire: {:.4f}, F1NonFire: {:4f}, AUC: {:4f}, AUPRC: {:4f} in {:.4f}m'.format(data, \n",
    "                                                                                  epoch_loss, running_corrects/len(dataloaders['lstm_bolam'][data].dataset),\n",
    "                                                                                  running_true_positives_fire/(running_true_positives_fire + running_false_positives_fire),\n",
    "                                                                                  running_true_positives_fire/(running_true_positives_fire + running_false_negatives_fire),\n",
    "                                                                                  running_true_positives_fire/(running_true_positives_fire + (1/2)*(running_false_positives_fire + running_false_negatives_fire)),\n",
    "                                                                                  running_true_positives_non_fire/(running_true_positives_non_fire + running_false_positives_non_fire),\n",
    "                                                                                  running_true_positives_non_fire/(running_true_positives_non_fire + running_false_negatives_non_fire),\n",
    "                                                                                  running_true_positives_non_fire/(running_true_positives_non_fire + (1/2)*(running_false_positives_non_fire + running_false_negatives_non_fire)),\n",
    "                                                                                  auc, aucpr, time_elapsed/60))\n",
    "\n",
    "    print('Confusion Matrix')\n",
    "    print(running_true_positives_non_fire, running_false_negatives_non_fire)\n",
    "    print(running_false_negatives_fire, running_true_positives_fire)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-dating",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meteo",
   "language": "python",
   "name": "meteo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
