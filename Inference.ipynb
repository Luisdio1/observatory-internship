{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "statistical-grant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import csv\n",
    "import xarray as xr\n",
    "import fsspec\n",
    "import zarr\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "from pytorch_lightning import LightningModule\n",
    "from torchmetrics.classification.accuracy import Accuracy\n",
    "from torchmetrics import AUC, ConfusionMatrix, AUROC, AveragePrecision\n",
    "from wildfire_forecasting.models.greece_fire_models import LSTM_fire_model, ConvLSTM_fire_model\n",
    "# from wildfire_forecasting.models.modules.greece_fire_models import LSTM_fire_model, ConvLSTM_fire_model \n",
    "\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "industrial-liquid",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = ['time',\n",
    " 'x',\n",
    " 'y',\n",
    "]\n",
    "\n",
    "all_dynamic_features = [\n",
    " '1 km 16 days NDVI',\n",
    " 'LST_Day_1km',\n",
    " 'LST_Night_1km',\n",
    " 'era5_max_d2m',\n",
    " 'era5_max_t2m',\n",
    " 'era5_max_sp',\n",
    " 'era5_max_tp',\n",
    " 'sminx',\n",
    " 'era5_max_wind_speed',\n",
    " 'era5_min_rh']\n",
    "\n",
    "all_static_features = [\n",
    " 'dem_mean',\n",
    " 'slope_mean',\n",
    " 'roads_distance',\n",
    " 'waterway_distance',\n",
    " 'population_density'\n",
    "]\n",
    "\n",
    "all_categorical_features = 'clc_vec'\n",
    "len_clc = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "verified-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_settings = {\n",
    "    'lstm' : {'dynamic_features':all_dynamic_features, 'static_features':all_static_features, 'hidden_size':64, 'lstm_layers':1, 'dropout':0.5},\n",
    "    'convlstm' : {'dynamic_features':all_dynamic_features, 'static_features':all_static_features, 'hidden_size':32, 'lstm_layers':1, 'dropout':0.5}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "moral-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Follow readme for downloading the models and complete the models path here\n",
    "models_path = Path.home() / 'hdd1/iprapas/uc3/models'\n",
    "model = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "generic-emperor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd1/diogenis/observatory/meteo/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/mnt/hdd1/diogenis/observatory/meteo/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTM_fire_model(\n",
       "  (model): SimpleLSTM(\n",
       "    (ln1): LayerNorm((25,), eps=1e-05, elementwise_affine=True)\n",
       "    (lstm): LSTM(25, 64, batch_first=True)\n",
       "    (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (drop1): Dropout(p=0.5, inplace=False)\n",
       "    (relu): ReLU()\n",
       "    (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (drop2): Dropout(p=0.5, inplace=False)\n",
       "    (fc3): Linear(in_features=32, out_features=2, bias=True)\n",
       "    (fc_nn): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=32, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (criterion): NLLLoss()\n",
       "  (train_accuracy): Accuracy()\n",
       "  (train_auc): AUROC()\n",
       "  (train_auprc): AveragePrecision()\n",
       "  (val_accuracy): Accuracy()\n",
       "  (val_auc): AUROC()\n",
       "  (val_auprc): AveragePrecision()\n",
       "  (test_accuracy): Accuracy()\n",
       "  (test_auc): AUROC()\n",
       "  (test_auprc): AveragePrecision()\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['lstm'] = LSTM_fire_model(**best_settings['lstm']).load_from_checkpoint(models_path / 'lstm.ckpt')\n",
    "model['lstm'].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "arabic-bicycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = Path.home() / 'hdd1/diogenis/observatory'\n",
    "# datacube_path = Path.home() / 'hdd1/skondylatos/uc3'\n",
    "\n",
    "# minmax_dataset_root = dataset_root / 'datasets'\n",
    "minmax_dataset_root = Path.home() / 'jh-shared/skondylatos/datasets'\n",
    "\n",
    "variable_dict_path = dataset_root / 'variable_dict.json' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "extended-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(variable_dict_path) as f:\n",
    "    variable_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "appointed-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(minmax_dataset_root / 'minmax_clc_v3.json') as f:\n",
    "    min_max_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "signed-nebraska",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireDataset_npy(Dataset):\n",
    "    def __init__(self, access_mode: str = 'temporal',\n",
    "                 problem_class: str = 'classification',\n",
    "                 train_val_test: str = 'test', dynamic_features: list = None, static_features: list = None,\n",
    "                 categorical_features: list = None, nan_fill: float = -1., neg_pos_ratio: int = 2, clc: str = None):\n",
    "        \"\"\"\n",
    "        @param access_mode: spatial, temporal or spatiotemporal\n",
    "        @param problem_class: classification or segmentation\n",
    "        @param train_val_test:\n",
    "                'train' gets samples from [2009-2018].\n",
    "                'val' gets samples from 2019.\n",
    "                test' get samples from 2020\n",
    "        @param dynamic_features: selects the dynamic features to return\n",
    "        @param static_features: selects the static features to return\n",
    "        @param categorical_features: selects the categorical features\n",
    "        @param nan_fill: Fills nan with the value specified here\n",
    "        \"\"\"\n",
    "        if static_features is None:\n",
    "            static_features = all_static_features\n",
    "        if dynamic_features is None:\n",
    "            dynamic_features = all_dynamic_features\n",
    "            \n",
    "        self.static_features = static_features\n",
    "        self.dynamic_features = dynamic_features\n",
    "        self.categorical_features = categorical_features\n",
    "        self.access_mode = access_mode\n",
    "        self.problem_class = problem_class\n",
    "        self.nan_fill = nan_fill\n",
    "        self.clc = clc\n",
    "        \n",
    "        assert problem_class in ['classification', 'segmentation']\n",
    "        if problem_class == 'classification':\n",
    "            self.target = 'burned'\n",
    "        else:\n",
    "            self.target = 'burned_areas'\n",
    "            \n",
    "        assert self.access_mode in ['spatial', 'temporal', 'spatiotemporal']\n",
    "        \n",
    "        dataset_path = dataset_root \n",
    "        \n",
    "        self.positives_list = list((dataset_path / 'positives').glob('*dynamic.npy'))\n",
    "        self.positives_list = list(zip(self.positives_list, [1] * (len(self.positives_list))))\n",
    "        \n",
    "        val_year = 2020\n",
    "        test_year = min(val_year + 1, 2021)\n",
    "\n",
    "        # self.train_positive_list = [(x, y) for (x, y) in self.positives_list if int(x.stem[:4]) < val_year]\n",
    "        # self.val_positive_list = [(x, y) for (x, y) in self.positives_list if int(x.stem[:4]) == val_year]\n",
    "        # self.test_positive_list = [(x, y) for (x, y) in self.positives_list if int(x.stem[:4]) == test_year]\n",
    "\n",
    "        self.negatives_list = list((dataset_path / 'negatives').glob('*dynamic.npy'))\n",
    "        self.negatives_list = list(zip(self.negatives_list, [0] * (len(self.negatives_list))))\n",
    "\n",
    "#         self.train_negative_list = random.sample(\n",
    "#             [(x, y) for (x, y) in self.negatives_list if int(x.stem[:4]) < val_year],\n",
    "#             len(self.train_positive_list) * neg_pos_ratio)\n",
    "#         self.val_negative_list = random.sample(\n",
    "#             [(x, y) for (x, y) in self.negatives_list if int(x.stem[:4]) == val_year],\n",
    "#             len(self.val_positive_list) * neg_pos_ratio)\n",
    "\n",
    "        self.test_negative_list = [(x, y) for (x, y) in self.negatives_list if int(x.stem[:4]) == test_year]\n",
    "        self.test_positive_list = random.sample(\n",
    "            [(x, y) for (x, y) in self.positives_list if int(x.stem[:4]) == test_year],\n",
    "            300)\n",
    "        \n",
    "#         try:\n",
    "#             if test_year == 2021 and train_val_test == 'test':\n",
    "#                 dataset_path = Path(str(dataset_path).replace('_v4', '_v5'))\n",
    "#             self.negatives_list = list((dataset_path / 'negatives_clc').glob('*dynamic.npy'))\n",
    "#             self.negatives_list = list(zip(self.negatives_list, [0] * (len(self.negatives_list))))\n",
    "#             self.test_negative_list = random.sample(\n",
    "#                 [(x, y) for (x, y) in self.negatives_list if int(x.stem[:4]) == test_year],\n",
    "#                 len(self.test_positive_list) * neg_pos_ratio)\n",
    "#         except ValueError as _:\n",
    "#             self.test_negative_list = [(x, y) for (x, y) in self.negatives_list if int(x.stem[:4]) == test_year]\n",
    "\n",
    "        self.dynamic_idxfeat = [(i, feat) for i, feat in enumerate(variable_dict['dynamic']) if\n",
    "                                feat in self.dynamic_features]\n",
    "        self.static_idxfeat = [(i, feat) for i, feat in enumerate(variable_dict['static']) if\n",
    "                               feat in self.static_features]\n",
    "        \n",
    "        self.dynamic_idx = [x for (x, _) in self.dynamic_idxfeat]\n",
    "        self.static_idx = [x for (x, _) in self.static_idxfeat]\n",
    "\n",
    "        if train_val_test == 'train':\n",
    "            print(f'Positives: {len(self.train_positive_list)} / Negatives: {len(self.train_negative_list)}')\n",
    "            self.path_list = self.train_positive_list + self.train_negative_list\n",
    "        elif train_val_test == 'val':\n",
    "            print(f'Positives: {len(self.val_positive_list)} / Negatives: {len(self.val_negative_list)}')\n",
    "\n",
    "            self.path_list = self.val_positive_list + self.val_negative_list\n",
    "        elif train_val_test == 'test':\n",
    "            print(f'Positives: {len(self.test_positive_list)} / Negatives: {len(self.test_negative_list)}')\n",
    "\n",
    "            self.path_list = self.test_positive_list + self.test_negative_list\n",
    "            \n",
    "        print(\"Dataset length\", len(self.path_list))\n",
    "        \n",
    "        random.shuffle(self.path_list)\n",
    "        \n",
    "        self.mm_dict = self._min_max_vec()\n",
    "\n",
    "    def _min_max_vec(self):\n",
    "        mm_dict = {'min': {}, 'max': {}}\n",
    "        for agg in ['min', 'max']:\n",
    "            if self.access_mode == 'spatial':\n",
    "                mm_dict[agg]['dynamic'] = np.ones((len(self.dynamic_features), 1, 1))\n",
    "                mm_dict[agg]['static'] = np.ones((len(self.static_features), 1, 1))\n",
    "                for i, (_, feat) in enumerate(self.dynamic_idxfeat):\n",
    "                    mm_dict[agg]['dynamic'][i, :, :] = min_max_dict[agg][self.access_mode][feat]\n",
    "                for i, (_, feat) in enumerate(self.static_idxfeat):\n",
    "                    mm_dict[agg]['static'][i, :, :] = min_max_dict[agg][self.access_mode][feat]\n",
    "\n",
    "            if self.access_mode == 'temporal':\n",
    "                mm_dict[agg]['dynamic'] = np.ones((1, len(self.dynamic_features)))\n",
    "                mm_dict[agg]['static'] = np.ones((len(self.static_features)))\n",
    "                for i, (_, feat) in enumerate(self.dynamic_idxfeat):\n",
    "                    mm_dict[agg]['dynamic'][:, i] = min_max_dict[agg][self.access_mode][feat]\n",
    "                for i, (_, feat) in enumerate(self.static_idxfeat):\n",
    "                    mm_dict[agg]['static'][i] = min_max_dict[agg][self.access_mode][feat]\n",
    "\n",
    "            if self.access_mode == 'spatiotemporal':\n",
    "                mm_dict[agg]['dynamic'] = np.ones((1, len(self.dynamic_features), 1, 1))\n",
    "                mm_dict[agg]['static'] = np.ones((len(self.static_features), 1, 1))\n",
    "                for i, (_, feat) in enumerate(self.dynamic_idxfeat):\n",
    "                    mm_dict[agg]['dynamic'][:, i, :, :] = min_max_dict[agg][self.access_mode][feat]\n",
    "                for i, (_, feat) in enumerate(self.static_idxfeat):\n",
    "                    mm_dict[agg]['static'][i, :, :] = min_max_dict[agg][self.access_mode][feat]\n",
    "        return mm_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, labels = self.path_list[idx]\n",
    "        dynamic = np.load(path)\n",
    "        static = np.load(str(path).replace('dynamic', 'static'))\n",
    "        \n",
    "        if self.access_mode == 'spatial':\n",
    "            dynamic = dynamic[self.dynamic_idx]\n",
    "            static = static[self.static_idx]\n",
    "        elif self.access_mode == 'temporal':\n",
    "            dynamic = dynamic[:, self.dynamic_idx, ...]\n",
    "            static = static[self.static_idx]\n",
    "        else:\n",
    "            dynamic = dynamic[:, self.dynamic_idx, ...]\n",
    "            static = static[self.static_idx]\n",
    "\n",
    "        def _min_max_scaling(in_vec, max_vec, min_vec):\n",
    "            return (in_vec - min_vec) / (max_vec - min_vec)\n",
    "\n",
    "        dynamic = _min_max_scaling(dynamic, self.mm_dict['max']['dynamic'], self.mm_dict['min']['dynamic'])\n",
    "        static = _min_max_scaling(static, self.mm_dict['max']['static'], self.mm_dict['min']['static'])\n",
    "\n",
    "        if self.access_mode == 'temporal':\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "                feat_mean = np.nanmean(dynamic, axis=0)\n",
    "                # Find indices that you need to replace\n",
    "                inds = np.where(np.isnan(dynamic))\n",
    "                # Place column means in the indices. Align the arrays using take\n",
    "                dynamic[inds] = np.take(feat_mean, inds[1])\n",
    "\n",
    "        elif self.access_mode == 'spatiotemporal':\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "                feat_mean = np.nanmean(dynamic, axis=(2, 3))\n",
    "                feat_mean = feat_mean[..., np.newaxis, np.newaxis]\n",
    "                feat_mean = np.repeat(feat_mean, dynamic.shape[2], axis=2)\n",
    "                feat_mean = np.repeat(feat_mean, dynamic.shape[3], axis=3)\n",
    "                dynamic = np.where(np.isnan(dynamic), feat_mean, dynamic)\n",
    "        if self.nan_fill:\n",
    "            dynamic = np.nan_to_num(dynamic, nan=self.nan_fill)\n",
    "            static = np.nan_to_num(static, nan=self.nan_fill)\n",
    "\n",
    "        if self.clc == 'mode':\n",
    "            clc = np.load(str(path).replace('dynamic', 'clc_mode'))\n",
    "        elif self.clc == 'vec':\n",
    "            clc = np.load(str(path).replace('dynamic', 'clc_vec'))\n",
    "            clc = np.nan_to_num(clc, nan=0)\n",
    "        else:\n",
    "            clc = 0\n",
    "        return dynamic, static, clc, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "roman-perth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positives: 300 / Negatives: 600\n",
      "Dataset length 900\n"
     ]
    }
   ],
   "source": [
    "cuda_device = 1\n",
    "positive_weight = 0.5\n",
    "device = torch.device(\"cuda:\" + str(cuda_device) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "weights = [1 - positive_weight, positive_weight]\n",
    "class_weights = torch.FloatTensor(weights)\n",
    "criterion = nn.NLLLoss(weight=class_weights)\n",
    "num_epochs=40\n",
    "\n",
    "dataloaders = {}\n",
    "\n",
    "dataloaders['lstm'] ={'test' : torch.utils.data.DataLoader(FireDataset_npy(train_val_test='test', access_mode = 'temporal', clc = 'vec'), batch_size=256, num_workers=16)}\n",
    "# dataloaders['lstm'] = {\n",
    "#     'train' : torch.utils.data.DataLoader(FireDataset_npy(train_val_test='train', access_mode = 'temporal', clc = 'vec'), batch_size=256, shuffle=True, num_workers=16),\n",
    "#     'val' : torch.utils.data.DataLoader(FireDataset_npy(train_val_test='val', access_mode = 'temporal', clc = 'vec'), batch_size=256, num_workers=16),\n",
    "#     'test': torch.utils.data.DataLoader(FireDataset_npy(train_val_test='test', access_mode = 'temporal', clc = 'vec'), batch_size=256, num_workers=16)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "everyday-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision_and_recall(output, labels, running_true_positives_fire, running_false_positives_fire, running_false_negatives_fire, running_true_positives_non_fire, running_false_positives_non_fire, running_false_negatives_non_fire):\n",
    "    for j in range(output.size()[0]):\n",
    "        if output[j] == 1 and labels[j] == 1:\n",
    "            running_true_positives_fire +=1\n",
    "        if output[j] == 1 and labels[j] == 0:\n",
    "            running_false_positives_fire +=1\n",
    "        if output[j] == 0 and labels[j] == 1:\n",
    "            running_false_negatives_fire +=1\n",
    "        if output[j] == 0 and labels[j] == 0:\n",
    "            running_true_positives_non_fire +=1\n",
    "        if output[j] == 0 and labels[j] == 1:\n",
    "            running_false_positives_non_fire +=1\n",
    "        if output[j] == 1 and labels[j] == 0:\n",
    "            running_false_negatives_non_fire +=1\n",
    "    return running_true_positives_fire, running_false_positives_fire, running_false_negatives_fire, running_true_positives_non_fire, running_false_positives_non_fire, running_false_negatives_non_fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "extended-latino",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  8.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6008, Accuracy: 0.7533, PrecisionFire: 0.5899, RecallFire: 0.8533, F1Fire: 0.697548, PrecisionNonFire: 0.9056, RecallNonFire: 0.7033, F1NonFire: 0.791745, AUC: 0.861811, AUPRC: 0.737316 in 0.0077m\n",
      "Confusion Matrix\n",
      "422 178\n",
      "44 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "since = time.time()\n",
    "\n",
    "preds = []\n",
    "true_labels = []\n",
    "running_loss = 0.0\n",
    "running_corrects = 0\n",
    "running_true_positives_fire = 0\n",
    "running_false_positives_fire = 0\n",
    "running_false_negatives_fire = 0\n",
    "running_true_positives_non_fire = 0\n",
    "running_false_positives_non_fire = 0\n",
    "running_false_negatives_non_fire = 0\n",
    "# Iterate over data.\n",
    "for i, (dynamic, static, clc, labels) in enumerate(tqdm(dataloaders['lstm']['test'])):\n",
    "    static = static.unsqueeze(1).repeat(1, dynamic.shape[1], 1)\n",
    "    clc = clc.unsqueeze(1).repeat(1, dynamic.shape[1], 1)\n",
    "    input_ = torch.cat([dynamic, static, clc], dim = 2).float()\n",
    "    with torch.set_grad_enabled(phase == 'train'):\n",
    "        outputs_list = []\n",
    "        outputs_list.append(model['lstm'](input_))\n",
    "        outputs = torch.stack(outputs_list, dim=1)\n",
    "        mean = outputs.mean(1)\n",
    "        loss = criterion(mean, labels)\n",
    "    # statistics\n",
    "    running_loss += loss.item() * dynamic.size(0)\n",
    "    output = mean\n",
    "\n",
    "    preds.append(output[:,1])\n",
    "    true_labels.append(labels)\n",
    "    output = torch.argmax(output, dim=1)\n",
    "\n",
    "    correct = (output == labels).float().sum()\n",
    "    running_corrects += correct\n",
    "\n",
    "    running_true_positives_fire, running_false_positives_fire, running_false_negatives_fire, running_true_positives_non_fire, running_false_positives_non_fire, running_false_negatives_non_fire = get_precision_and_recall(output, labels, running_true_positives_fire, running_false_positives_fire, running_false_negatives_fire, running_true_positives_non_fire, running_false_positives_non_fire, running_false_negatives_non_fire)\n",
    "\n",
    "preds = torch.cat(preds, dim=0).detach().cpu().numpy()\n",
    "true_labels = torch.cat(true_labels, dim=0).detach().cpu().numpy()\n",
    "    \n",
    "auc = roc_auc_score(true_labels, preds)\n",
    "aucpr = average_precision_score(true_labels, preds)\n",
    "\n",
    "epoch_loss = running_loss / len(dataloaders['lstm']['test'].dataset)\n",
    "time_elapsed = time.time() - since\n",
    "# try:\n",
    "print('{} Loss: {:.4f}, Accuracy: {:.4f}, PrecisionFire: {:.4f}, RecallFire: {:.4f}, F1Fire: {:4f}, PrecisionNonFire: {:.4f}, RecallNonFire: {:.4f}, F1NonFire: {:4f}, AUC: {:4f}, AUPRC: {:4f} in {:.4f}m'.format(phase, \n",
    "                                                                                  epoch_loss, running_corrects/len(dataloaders['lstm']['test'].dataset),\n",
    "                                                                                  running_true_positives_fire/(running_true_positives_fire + running_false_positives_fire),\n",
    "                                                                                  running_true_positives_fire/(running_true_positives_fire + running_false_negatives_fire),\n",
    "                                                                                  running_true_positives_fire/(running_true_positives_fire + (1/2)*(running_false_positives_fire + running_false_negatives_fire)),\n",
    "                                                                                  running_true_positives_non_fire/(running_true_positives_non_fire + running_false_positives_non_fire),\n",
    "                                                                                  running_true_positives_non_fire/(running_true_positives_non_fire + running_false_negatives_non_fire),\n",
    "                                                                                  running_true_positives_non_fire/(running_true_positives_non_fire + (1/2)*(running_false_positives_non_fire + running_false_negatives_non_fire)),\n",
    "                                                                                  auc, aucpr, time_elapsed/60))\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(running_true_positives_non_fire, running_false_negatives_non_fire)\n",
    "print(running_false_negatives_fire, running_true_positives_fire)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-rapid",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meteo",
   "language": "python",
   "name": "meteo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
