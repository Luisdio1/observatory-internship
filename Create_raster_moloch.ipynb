{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "neither-highway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: ecCodes 2.21.0 or higher is recommended. You are running version 2.16.0\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import torch\n",
    "import wildfire_forecasting.models.greece_fire_models as gfm\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from wildfire_forecasting.models.greece_fire_models import combine_dynamic_static_inputs\n",
    "import datetime\n",
    "import rasterio\n",
    "import rioxarray as rxr\n",
    "import utils\n",
    "import config\n",
    "import argparse\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.offsetbox\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "challenging-pierre",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = Path.home() / 'hdd1/iprapas/uc3/datasets_v4'\n",
    "min_max_file = dataset_root / 'minmax_clc.json'\n",
    "variable_file = dataset_root / 'variable_dict.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "institutional-george",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(min_max_file) as f:\n",
    "    min_max_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "spiritual-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_renaming = {\n",
    "    'max_t2m': 'era5_max_t2m',\n",
    "    'max_u10': 'era5_max_u10',\n",
    "    'max_v10': 'era5_max_v10',\n",
    "    'max_tp': 'era5_max_tp',\n",
    "    'max_sp': 'era5_max_sp',\n",
    "    'max_d2m': 'era5_max_d2m',\n",
    "    'max_r2': None,\n",
    "    'max_gust': None,\n",
    "    'max_wind_speed': 'era5_max_wind_speed',\n",
    "    'max_rh': 'era5_max_rh',\n",
    "    'min_t2m': 'era5_min_t2m',\n",
    "    'min_u10': None,\n",
    "    'min_v10': None,\n",
    "    'min_tp': None,\n",
    "    'min_sp': None,\n",
    "    'min_d2m': None,\n",
    "    'min_r2': None,\n",
    "    'min_gust': None,\n",
    "    'min_wind_speed': None,\n",
    "    'min_rh': 'era5_min_rh',\n",
    "    'lst_day': 'LST_Day_1km',\n",
    "    'lst_night': 'LST_Night_1km',\n",
    "    'sminx':'sminx',\n",
    "    'EVI': '1 km 16 days EVI',\n",
    "    'ndvi': '1 km 16 days NDVI',\n",
    "    'DEM': 'dem_mean',\n",
    "    'SLOPE': 'slope_mean',\n",
    "    'ROAD_DISTANCE': 'roads_distance',\n",
    "    'POP_DENS_2021': 'population_density',\n",
    "    'WATERWAY_DISTANCE' : 'waterway_distance'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hungry-neutral",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixel_feature_ds(the_ds, t=0, x=0, y=0, access_mode='temporal', patch_size=0, lag=0):\n",
    "    assert access_mode in ['spatial', 'temporal', 'spatiotemporal']\n",
    "    assert lag >= 0 and patch_size >= 0 and t >= 0 and x >= 0 and y >= 0\n",
    "    patch_half = patch_size // 2\n",
    "    assert x >= patch_half and x + patch_half < the_ds.dims['x']\n",
    "    assert y >= patch_half and y + patch_half < the_ds.dims['y']\n",
    "    #     len_x = ds.dims['x'] - patch_size\n",
    "    #     len_y = ds.dims['y'] - patch_size\n",
    "    if access_mode == 'spatiotemporal':\n",
    "        block = the_ds.isel(time=slice(t + 1 - lag, t + 1), x=slice(x - patch_half, x + patch_half + 1),\n",
    "                            y=slice(y - patch_half, y + patch_half + 1))  # .reset_index(['x', 'y', 'time'])\n",
    "    elif access_mode == 'temporal':\n",
    "        block = the_ds.isel(time=slice(0, t + 1), x=x, y=y).reset_index(['time'])\n",
    "    elif access_mode == 'spatial':\n",
    "        block = the_ds.isel(x=slice(x - patch_half, x + patch_half + 1),\n",
    "                            y=slice(y - patch_half, y + patch_half + 1))  # .reset_index(['x', 'y'])\n",
    "\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ideal-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaling(chunk, feat_name, access_mode, clip=True):\n",
    "    '''\n",
    "    (x - min)/(max - min)\n",
    "    '''\n",
    "    feat_name_old = feature_renaming[feat_name]\n",
    "    minimum = min_max_dict['min'][access_mode][feat_name_old]\n",
    "    maximum = min_max_dict['max'][access_mode][feat_name_old]\n",
    "    feat = chunk[feat_name]\n",
    "#     if feat_name == 'max_tp':\n",
    "#         feat = feat / 1000\n",
    "    if clip:\n",
    "        feat = np.clip(feat, a_min=minimum, a_max=maximum)\n",
    "    return (feat - minimum) / (maximum - minimum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "extraordinary-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixel_feature_vector(the_ds, t=0, x=0, y=0, access_mode='temporal', patch_size=0, lag=0,\n",
    "                             dynamic_features=None,\n",
    "                             static_features=None, override_whole=False, scaling='minmax',\n",
    "                             clc='clc_vec'):\n",
    "    if override_whole:\n",
    "        chunk = the_ds\n",
    "    else:\n",
    "        chunk = get_pixel_feature_ds(the_ds, t=t, x=x, y=y, access_mode=access_mode, patch_size=patch_size, lag=lag)\n",
    "\n",
    "    if scaling == 'minmax':\n",
    "        dynamic = np.stack([min_max_scaling(chunk, feature, access_mode) for feature in dynamic_features])\n",
    "        static = np.stack([min_max_scaling(chunk, feature, access_mode) for feature in static_features])\n",
    "\n",
    "    if 'temp' in access_mode:\n",
    "        dynamic = np.moveaxis(dynamic, 0, 1)\n",
    "    clc_vec = 0\n",
    "    if clc == 'clc_vec':\n",
    "        clc_vec = np.stack([chunk[f'CLC_2018_{i}'] for i in range(10)])\n",
    "\n",
    "    return dynamic, static, clc_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "integrated-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireDatasetWholeDay(Dataset):\n",
    "    def __init__(self, ds, access_mode='temporal', problem_class='classification', patch_size=0, lag=10,\n",
    "                 dynamic_features=None,\n",
    "                 static_features=None, nan_fill=-1.0, clc=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            dynamic_transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        assert access_mode in ['temporal', 'spatial', 'spatiotemporal']\n",
    "        assert problem_class in ['classification', 'segmentation']\n",
    "        self.problem_class = problem_class\n",
    "        self.override_whole = problem_class == 'segmentation'\n",
    "        self.ds = ds\n",
    "        self.ds = self.ds.load()\n",
    "        print(\"Dataset loaded...\")\n",
    "        pixel_range = patch_size // 2\n",
    "        self.pixel_range = pixel_range\n",
    "        self.len_x = self.ds.dims['x']\n",
    "        self.len_y = self.ds.dims['y']\n",
    "        if access_mode == 'spatial':\n",
    "            year = pd.DatetimeIndex([self.ds['time'].values]).year[0]\n",
    "        else:\n",
    "            year = pd.DatetimeIndex([self.ds['time'][0].values]).year[0]\n",
    "\n",
    "        self.patch_size = patch_size\n",
    "        self.lag = lag\n",
    "        self.access_mode = access_mode\n",
    "        self.nan_fill = nan_fill\n",
    "        self.dynamic_features = dynamic_features\n",
    "        self.static_features = static_features\n",
    "        self.clc = clc\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.problem_class == 'segmentation':\n",
    "            return 1\n",
    "        return self.len_x * self.len_y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        y = idx // self.len_x + self.pixel_range\n",
    "        x = idx % self.len_x + self.pixel_range\n",
    "\n",
    "        dynamic, static, clc = get_pixel_feature_vector(self.ds, self.lag, x,\n",
    "                                                        y, self.access_mode, self.patch_size,\n",
    "                                                        self.lag,\n",
    "                                                        self.dynamic_features,\n",
    "                                                        self.static_features,\n",
    "                                                        self.override_whole, clc=self.clc)\n",
    "        if self.access_mode == 'temporal':\n",
    "            feat_mean = np.nanmean(dynamic, axis=0)\n",
    "            # Find indices that you need to replace\n",
    "            inds = np.where(np.isnan(dynamic))\n",
    "            # Place column means in the indices. Align the arrays using take\n",
    "            dynamic[inds] = np.take(feat_mean, inds[1])\n",
    "            \n",
    "        dynamic = np.nan_to_num(dynamic, nan=self.nan_fill)\n",
    "        static = np.nan_to_num(static, nan=self.nan_fill)\n",
    "    \n",
    "        return dynamic, static, clc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "individual-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Συνάρτηση που παίρνει σαν input την ημερομηνία και γυρνάει το dataarray με τα predictions Που μετά μπορείς να κάνεις πλοτ\n",
    "def predict_lstm(plot_date, stats, model):\n",
    "    #Εδώ θα βάλεις το path του μοντέλου\n",
    "    if model=='moloch':\n",
    "        model_path = '/home/jupyter-diogenis/hdd1/diogenis/observatory/wildfire_forecasting/logs/runs/2022-09-20/23-57-45/checkpoints/last.ckpt'\n",
    "    else:\n",
    "        model_path = '/home/jupyter-diogenis/hdd1/iprapas/uc3/models/lstm.ckpt'\n",
    "\n",
    "    # Εδω θα χρησιμοποιήσεις το αρχικό cube με τα ERA5_land μία φορά και μετά θα αλλάξεις στο cube τα meteo με τα meteo από το dwd για όλες τις μέρες και όλα τα άλλα variables θα τα αφήσεις ίδια\n",
    "    dc_path = Path.home() / 'hdd1/iprapas/FireCube_time4_x70_y52.nc'\n",
    "    input_ds = xr.open_dataset(dc_path)\n",
    "    input_ds = input_ds.sel(time = slice(plot_date - pd.Timedelta('10 days'), plot_date))\n",
    "    if stats == 'moloch':\n",
    "        moloch_ds = xr.open_dataset(Path.home() / 'hdd1/diogenis/observatory/moloch_meteo.nc')\n",
    "        for i in range(10):\n",
    "            date_to_change = plot_date - pd.Timedelta(str(i) + ' days')\n",
    "            input_ds['max_t2m'].loc[dict(time= str(date_to_change.date()))] = moloch_ds.sel(time = str(date_to_change.date()))['max_t2m'].values\n",
    "            input_ds['max_wind_speed'].loc[dict(time= str(date_to_change.date()))] = moloch_ds.sel(time = str(date_to_change.date()))['max_wind_speed'].values\n",
    "            input_ds['max_d2m'].loc[dict(time= str(date_to_change.date()))] = moloch_ds.sel(time = str(date_to_change.date()))['max_d2m'].values\n",
    "            input_ds['min_rh'].loc[dict(time= str(date_to_change.date()))] = moloch_ds.sel(time = str(date_to_change.date()))['min_relhum_2m'].values\n",
    "        \n",
    "    \n",
    "\n",
    "    static_features = ['DEM', 'SLOPE', 'ROAD_DISTANCE', 'POP_DENS_2021', 'WATERWAY_DISTANCE']\n",
    "\n",
    "    clc_template = 'CLC_2018_{0}'\n",
    "\n",
    "#     dynamic_features = None\n",
    "\n",
    "    day = plot_date\n",
    "    \n",
    "    # Εδώ βάλε τα features που θέλεις\n",
    "    dynamic_features = [\n",
    "        'ndvi',\n",
    "        'lst_day',\n",
    "        'lst_night',\n",
    "        'max_d2m',\n",
    "        'max_t2m',\n",
    "        'max_sp',\n",
    "        'max_tp',\n",
    "        'max_wind_speed',\n",
    "        'min_rh',\n",
    "        'sminx'\n",
    "    ]\n",
    "\n",
    "#     all_ds = xr.open_dataset(dc_path)\n",
    "    # Εδώ κράτα τις 10 τελευταίες μέρες\n",
    "    # ds['time'] = ds['time'] + pd.Timedelta('1 days')\n",
    "#     all_ds = all_ds.isel\n",
    "#  #  #   input_ds = input_ds.sel(time = slice(plot_date - pd.Timedelta('10 days'), plot_date))\n",
    "\n",
    "    model = gfm.LSTM_fire_model.load_from_checkpoint(model_path)\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    torch_ds_clc = FireDatasetWholeDay(input_ds, access_mode='temporal', problem_class='classification', patch_size=0,\n",
    "                                       lag=10,\n",
    "                                       dynamic_features=dynamic_features,\n",
    "                                       static_features=static_features, nan_fill=-1.0, clc = 'clc_vec')\n",
    "\n",
    "    dl_clc = DataLoader(torch_ds_clc, batch_size=2048, shuffle=False, num_workers=16)\n",
    "\n",
    "    all_preds = []\n",
    "    model = model.to('cpu')\n",
    "    for batch_idx, (dynamic, static, clc) in tqdm(enumerate(dl_clc), total=len(dl_clc)):\n",
    "        # if clc_check:\n",
    "        inputs = combine_dynamic_static_inputs(dynamic, static, clc, 'temporal')\n",
    "        # else:\n",
    "#             inputs = combine_dynamic_static_inputs(dynamic, static, None, 'temporal')\n",
    "        inputs = inputs.to('cpu')\n",
    "        preds = torch.exp(model(inputs))\n",
    "        all_preds.append(preds.detach().cpu().numpy())\n",
    "    pred_img_clc = np.concatenate(all_preds)\n",
    "\n",
    "    len_x, len_y = len(input_ds['x']), len(input_ds['y'])\n",
    "    y = pred_img_clc[:, 1].reshape(len_y, len_x)\n",
    "    \n",
    "    clc_to_include = [2, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
    "    clc = np.isin(input_ds['CLC_2018'].values, clc_to_include, invert=True)\n",
    "    y[clc] = float('Nan')\n",
    "\n",
    "    pop_den_path = Path.home() / 'jh-shared/iprapas/uc3/pop_density/grc_pd_2020_1km.nc'\n",
    "    pop_den = xr.open_dataset(pop_den_path).squeeze().interp(x=input_ds['x'], y= input_ds['y'], method='nearest')\n",
    "    pop_den = np.isnan(pop_den['band_data'].values)\n",
    "    y[pop_den] = float('Nan')\n",
    "\n",
    "    da = xr.DataArray(\n",
    "        data=y,\n",
    "        dims=[\"y\", \"x\"],\n",
    "        coords=dict(\n",
    "            x=input_ds['x'],\n",
    "            y=input_ds['y'],\n",
    "        ))\n",
    "    da.rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "\n",
    "    return da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "affecting-seeking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 602/602 [06:26<00:00,  1.56it/s]\n"
     ]
    }
   ],
   "source": [
    "datetime_str = '2021/07/28 12:00:00'\n",
    "date = datetime.strptime(datetime_str, '%Y/%m/%d %H:%M:%S')\n",
    "preds_era5 = predict_lstm(date, 'era5', 'moloch')\n",
    "preds_era5.rio.to_raster(Path.home() / 'hdd1/diogenis/observatory/Plots/era5_2021_07_28_moloch.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "presidential-ultimate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 602/602 [06:28<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "datetime_str = '2021/08/01 12:00:00'\n",
    "date = datetime.strptime(datetime_str, '%Y/%m/%d %H:%M:%S')\n",
    "preds_era5 = predict_lstm(date, 'era5', 'moloch')\n",
    "preds_era5.rio.to_raster(Path.home() / 'hdd1/diogenis/observatory/Plots/era5_2021_08_01_moloch.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ignored-reflection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 602/602 [06:28<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "datetime_str = '2021/08/10 12:00:00'\n",
    "date = datetime.strptime(datetime_str, '%Y/%m/%d %H:%M:%S')\n",
    "preds_era5 = predict_lstm(date, 'era5', 'moloch')\n",
    "preds_era5.rio.to_raster(Path.home() / 'hdd1/diogenis/observatory/Plots/era5_2021_08_10_moloch.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "thrown-entrance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 602/602 [06:26<00:00,  1.56it/s]\n"
     ]
    }
   ],
   "source": [
    "datetime_str = '2021/08/21 12:00:00'\n",
    "date = datetime.strptime(datetime_str, '%Y/%m/%d %H:%M:%S')\n",
    "preds_era5 = predict_lstm(date, 'era5', 'moloch')\n",
    "preds_era5.rio.to_raster(Path.home() / 'hdd1/diogenis/observatory/Plots/era5_2021_08_21_moloch.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "incoming-cement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 602/602 [06:28<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "datetime_str = '2021/07/28 12:00:00'\n",
    "date = datetime.strptime(datetime_str, '%Y/%m/%d %H:%M:%S')\n",
    "preds_dwd = predict_lstm(date, 'moloch', 'moloch')\n",
    "preds_dwd.rio.to_raster(Path.home() / 'hdd1/diogenis/observatory/Plots/moloch_2021_07_28_moloch.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "analyzed-latitude",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 602/602 [06:58<00:00,  1.44it/s]\n"
     ]
    }
   ],
   "source": [
    "datetime_str = '2021/07/28 12:00:00'\n",
    "date = datetime.strptime(datetime_str, '%Y/%m/%d %H:%M:%S')\n",
    "preds_dwd = predict_lstm(date, 'moloch', 'lstm')\n",
    "preds_dwd.rio.to_raster(Path.home() / 'hdd1/diogenis/observatory/Plots/moloch_2021_07_28_lstm.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "certified-poison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 602/602 [06:29<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "datetime_str = '2021/08/01 12:00:00'\n",
    "date = datetime.strptime(datetime_str, '%Y/%m/%d %H:%M:%S')\n",
    "preds_dwd = predict_lstm(date, 'moloch', 'moloch')\n",
    "preds_dwd.rio.to_raster(Path.home() / 'hdd1/diogenis/observatory/Plots/moloch_2021_08_01_moloch.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "confidential-entity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 602/602 [07:01<00:00,  1.43it/s]\n"
     ]
    }
   ],
   "source": [
    "datetime_str = '2021/08/01 12:00:00'\n",
    "date = datetime.strptime(datetime_str, '%Y/%m/%d %H:%M:%S')\n",
    "preds_dwd = predict_lstm(date, 'moloch', 'lstm')\n",
    "preds_dwd.rio.to_raster(Path.home() / 'hdd1/diogenis/observatory/Plots/moloch_2021_08_01_lstm.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fallen-biology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 602/602 [06:29<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "datetime_str = '2021/08/10 12:00:00'\n",
    "date = datetime.strptime(datetime_str, '%Y/%m/%d %H:%M:%S')\n",
    "preds_dwd = predict_lstm(date, 'moloch', 'moloch')\n",
    "preds_dwd.rio.to_raster(Path.home() / 'hdd1/diogenis/observatory/Plots/moloch_2021_08_10_moloch.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "unauthorized-helen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 602/602 [07:00<00:00,  1.43it/s]\n"
     ]
    }
   ],
   "source": [
    "datetime_str = '2021/08/10 12:00:00'\n",
    "date = datetime.strptime(datetime_str, '%Y/%m/%d %H:%M:%S')\n",
    "preds_dwd = predict_lstm(date, 'moloch', 'lstm')\n",
    "preds_dwd.rio.to_raster(Path.home() / 'hdd1/diogenis/observatory/Plots/moloch_2021_08_10_lstm.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "running-approach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 602/602 [06:29<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "datetime_str = '2021/08/21 12:00:00'\n",
    "date = datetime.strptime(datetime_str, '%Y/%m/%d %H:%M:%S')\n",
    "preds_dwd = predict_lstm(date, 'moloch', 'moloch')\n",
    "preds_dwd.rio.to_raster(Path.home() / 'hdd1/diogenis/observatory/Plots/moloch_2021_08_21_moloch.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "copyrighted-belle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 602/602 [06:59<00:00,  1.44it/s]\n"
     ]
    }
   ],
   "source": [
    "datetime_str = '2021/08/21 12:00:00'\n",
    "date = datetime.strptime(datetime_str, '%Y/%m/%d %H:%M:%S')\n",
    "preds_dwd = predict_lstm(date, 'moloch', 'lstm')\n",
    "preds_dwd.rio.to_raster(Path.home() / 'hdd1/diogenis/observatory/Plots/moloch_2021_08_21_lstm.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-conducting",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meteo",
   "language": "python",
   "name": "meteo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
